{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **训练 Traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_sb3.py  Simplification\n",
    "from tools.train import QuadrupedTrainer\n",
    "\n",
    "train = QuadrupedTrainer(algorithm=\"SAC\", \n",
    "                         num_envs=1,                            # num_envs\n",
    "                         load_nn=False)    \n",
    "train.set_env_config(motor_control_mode     =\"CPG\",             # Motor control mode\n",
    "                     task_env               =\"FWD_LOCOMOTION\",  # Task\n",
    "                     observation_space_mode =\"LR_COURSE_OBS\",   # Observation space \n",
    "                     add_noise              = True,\n",
    "                     terrain                = None,\n",
    "                     )\n",
    "train.train(total_timesteps=1000000)                            # maximum training timesteps\n",
    "train.save_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **测试 Simulation Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented observation spaces for deep reinforcement learning: \n",
    "#   \"DEFAULT\":    motor angles and velocities, body orientation\n",
    "#   \"LR_COURSE_OBS\":  [#0000FF TODO: what should you include? what is reasonable to measure on the real system? CPG states?] \n",
    "\n",
    "# Tasks to be learned with reinforcement learning\n",
    "#     - \"FWD_LOCOMOTION\"\n",
    "#         reward forward progress only\n",
    "#     - \"FLAGRUN\"\n",
    "#         move to goal, once reached, a new goal is randomly selected.\n",
    "#     - \"LR_COURSE_TASK\" \n",
    "#         [#0000FF TODO: what should you train for?]\n",
    "#         Ideally we want to command A1 to run in any direction while expending minimal energy\n",
    "#         How will you construct your reward function? \n",
    "\n",
    "# Motor control modes:\n",
    "#   - \"TORQUE\": \n",
    "#         supply raw torques to each motor (12)\n",
    "#   - \"PD\": \n",
    "#         supply desired joint positions to each motor (12)\n",
    "#         torques are computed based on the joint position/velocity error\n",
    "#   - \"CARTESIAN_PD\": \n",
    "#         supply desired foot positions for each leg (12)\n",
    "#         torques are computed based on the foot position/velocity error\n",
    "#   - \"CPG\": \n",
    "#         supply desired CPG state modulations (8), mapped to foot positions\n",
    "#         torques are computed based on inverse kinematics + joint PD (or you can add Cartesian PD)\n",
    "\n",
    "# Terrain types:\n",
    "#   -  None\n",
    "#   - \"SLOPES\":\n",
    "#   - \"STAIRS\":\n",
    "#   - \"GAPS\":\n",
    "#   - \"RANDOM\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model: ./logs/intermediate_models/112624150725_cpg_rl_120k\\rl_model_90000_steps.zip\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m      8\u001b[0m test\u001b[38;5;241m.\u001b[39mset_env_config(render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      9\u001b[0m                     record_video\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m     10\u001b[0m                     motor_control_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                     add_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                     )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# test.load_plots()        # plot rewards\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# run simulation\u001b[39;00m\n",
      "File \u001b[1;32md:\\EPFL\\Course\\[MICRO-507] legged robot\\Project 2\\tools\\test.py:101\u001b[0m, in \u001b[0;36mQuadrupedSimulation.load_and_run\u001b[1;34m(self, steps, deterministic)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m    100\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m--> 101\u001b[0m     obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dones:\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py:181\u001b[0m, in \u001b[0;36mVecNormalize.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Apply sequence of actions to sequence of environments\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    actions -> (observations, rewards, dones)\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    where ``dones`` is a boolean vector indicating whether each element is new.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m))  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mold_obs \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MATH-286-Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:234\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     warn(\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGym v21 environment do not accept options as a reset parameter, options=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     )\n\u001b[1;32m--> 234\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32md:\\EPFL\\Course\\[MICRO-507] legged robot\\Project 2\\env\\quadruped_gym_env.py:663\u001b[0m, in \u001b[0;36mQuadrupedGymEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    661\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gaps(num_gaps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, gap_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, between_gaps_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terrain \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRANDOM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_random_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terrain,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not implemented\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\EPFL\\Course\\[MICRO-507] legged robot\\Project 2\\env\\quadruped_gym_env.py:902\u001b[0m, in \u001b[0;36mQuadrupedGymEnv.add_random_boxes\u001b[1;34m(self, num_rand, z_height)\u001b[0m\n\u001b[0;32m    899\u001b[0m   block2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pybullet_client\u001b[38;5;241m.\u001b[39mcreateMultiBody(baseMass\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,baseCollisionShapeIndex \u001b[38;5;241m=\u001b[39m sh_colBox,\n\u001b[0;32m    900\u001b[0m                         basePosition \u001b[38;5;241m=\u001b[39m [x[i],y[i],z[i]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m],baseOrientation\u001b[38;5;241m=\u001b[39morn)\n\u001b[0;32m    901\u001b[0m   \u001b[38;5;66;03m# set friction coeff\u001b[39;00m\n\u001b[1;32m--> 902\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pybullet_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchangeDynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlateralFriction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ground_mu_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;66;03m# add walls \u001b[39;00m\n\u001b[0;32m    905\u001b[0m orn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pybullet_client\u001b[38;5;241m.\u001b[39mgetQuaternionFromEuler([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31merror\u001b[0m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "# load_sb3.py 简化\n",
    "from tools.test import QuadrupedSimulation\n",
    "\n",
    "# 配置 Settings\n",
    "test = QuadrupedSimulation(algorithm=\"SAC\", \n",
    "                           log_dir=\"./logs/intermediate_models/112624150725_cpg_rl_120k\")\n",
    "\n",
    "test.set_env_config(render=True, \n",
    "                    record_video=False, \n",
    "                    motor_control_mode=\"CPG\", \n",
    "                    task_env=\"FWD_LOCOMOTION\", \n",
    "                    observation_space_mode=\"LR_COURSE_OBS\",\n",
    "                    terrain=\"RANDOM\",\n",
    "                    add_noise=False,\n",
    "                    )\n",
    "\n",
    "# test.load_plots()        # plot rewards\n",
    "test.load_and_run()      # run simulation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
